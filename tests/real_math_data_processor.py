# -*- coding: utf-8 -*-
"""Enhanced Real Math Data Processor - Questions-Gen Optimized

Enhanced math data processor specifically designed for Questions-Gen model training objectives.

Key Optimizations:
1. Competition-level problem filtering and classification
2. Problem quality assessment and scoring
3. Difficulty progression and knowledge point mapping  
4. GRPO reward-compatible data structures
5. DeepSeek-R1 teacher model integration support
6. Coordinated variation training data generation
"""

import pandas as pd
import numpy as np
import random
import re
from datasets import Dataset, load_dataset
from typing import List, Dict, Tuple, Optional
import json
import math
from sklearn.feature_extraction.text import TfidfVectorizer

# å®‰å…¨å¯¼å…¥ unslothï¼ˆColab å…¼å®¹æ€§ï¼‰
try:
    from unsloth.chat_templates import standardize_sharegpt
    UNSLOTH_AVAILABLE = True
    print("âœ… Unslothåº“å·²åŠ è½½")
except ImportError:
    UNSLOTH_AVAILABLE = False
    print("âš ï¸ Unslothåº“æœªæ‰¾åˆ°ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
    
    # å¤‡ç”¨çš„standardize_sharegptå‡½æ•°
    def standardize_sharegpt(dataset):
        """å¤‡ç”¨çš„æ ‡å‡†åŒ–å‡½æ•°ï¼Œé€‚ç”¨äºæ²¡æœ‰unslothçš„ç¯å¢ƒ"""
        if 'conversations' in dataset.column_names:
            return dataset
        elif 'messages' in dataset.column_names:
            # å¦‚æœæ˜¯messagesæ ¼å¼ï¼Œè½¬æ¢ä¸ºconversations
            def convert_messages_to_conversations(example):
                return {'conversations': example['messages']}
            return dataset.map(convert_messages_to_conversations)
        else:
            # å‡è®¾æ•°æ®å·²ç»æ˜¯æ­£ç¡®æ ¼å¼
            return dataset

class EnhancedMathDataProcessor:
    """å¢å¼ºç‰ˆæ•°å­¦æ•°æ®å¤„ç†å™¨ - ä¸“ä¸ºQuestions-Genæ¨¡å‹ä¼˜åŒ–"""
    
    def __init__(self, tokenizer=None):
        self.tokenizer = tokenizer
        self.reasoning_dataset = None
        self.non_reasoning_dataset = None
        self.reasoning_conversations = None
        self.non_reasoning_conversations = None
        self.combined_dataset = None
        
        # Questions-Genä¸“ç”¨å¢å¼ºåŠŸèƒ½
        self.competition_problems = []
        self.difficulty_categories = {
            'basic': [],
            'intermediate': [],
            'advanced': [],
            'olympiad': []
        }
        self.knowledge_mapping = {}
        self.quality_scores = {}
        
        # è´¨é‡è¯„ä¼°å·¥å…·
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        
    def load_real_datasets(self):
        """åŠ è½½çœŸå®æ•°æ®é›†ï¼Œå¢å¼ºç«èµ›é—®é¢˜ç­›é€‰"""
        print("ğŸ”„ åŠ è½½çœŸå®æ•°æ®é›†ï¼ˆå¢å¼ºç«èµ›é—®é¢˜ç­›é€‰ï¼‰...")
        
        try:
            print("ğŸ“š åŠ è½½OpenMathReasoning-miniæ•°æ®é›†...")
            self.reasoning_dataset = load_dataset("unsloth/OpenMathReasoning-mini", split = "cot")
            print(f"âœ… æ¨ç†æ•°æ®é›†åŠ è½½: {len(self.reasoning_dataset)} æ¡ç›®")
            
            print("ğŸ“š åŠ è½½FineTome-100kæ•°æ®é›†...")
            self.non_reasoning_dataset = load_dataset("mlabonne/FineTome-100k", split = "train")
            print(f"âœ… å¯¹è¯æ•°æ®é›†åŠ è½½: {len(self.non_reasoning_dataset)} æ¡ç›®")
            
            # å¢å¼ºï¼šæå–å’Œåˆ†ç±»ç«èµ›çº§é—®é¢˜
            print("ğŸ” ç­›é€‰å’Œåˆ†ç±»ç«èµ›é—®é¢˜...")
            self._extract_competition_problems()
            
            return True
            
        except Exception as e:
            raise RuntimeError(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}. è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ä½¿ç”¨HFé•œåƒã€‚ä¸æ”¯æŒé™çº§åˆ°æ¨¡æ‹Ÿæ•°æ®ã€‚")
    
    def _extract_competition_problems(self):
        """æå–å’Œåˆ†ç±»ç«èµ›çº§é—®é¢˜"""
        competition_keywords = [
            'prove', 'find all', 'determine', 'show that', 'verify',
            'olympiad', 'competition', 'contest', 'amc', 'aime', 'usamo',
            'polynomial', 'inequality', 'optimization', 'combinatorics',
            'number theory', 'geometry', 'calculus', 'linear algebra'
        ]
        
        print(f"ğŸ”„ åˆ†æ {len(self.reasoning_dataset)} ä¸ªé—®é¢˜çš„ç«èµ›ç›¸å…³æ€§...")
        
        for i, item in enumerate(self.reasoning_dataset):
            if 'problem' in item and 'generated_solution' in item:
                problem = item['problem'].lower()
                solution = item['generated_solution']
                
                # æ£€æŸ¥ç«èµ›çº§ç‰¹å¾
                competition_score = self._calculate_competition_score(problem, solution)
                difficulty_level = self._assess_difficulty_level(problem, solution)
                knowledge_points = self._extract_detailed_knowledge_points(problem)
                
                if competition_score > 0.3:  # ç«èµ›ç›¸å…³æ€§é˜ˆå€¼
                    problem_data = {
                        'index': i,
                        'problem': item['problem'],
                        'solution': solution,
                        'competition_score': competition_score,
                        'difficulty_level': difficulty_level,
                        'knowledge_points': knowledge_points,
                        'quality_score': self._calculate_quality_score(item['problem'], solution)
                    }
                    
                    self.competition_problems.append(problem_data)
                    self.difficulty_categories[difficulty_level].append(problem_data)
        
        print(f"âœ… æå– {len(self.competition_problems)} ä¸ªç«èµ›çº§é—®é¢˜")
        for level, problems in self.difficulty_categories.items():
            print(f"  ğŸ“Š {level.capitalize()}: {len(problems)} ä¸ªé—®é¢˜")
    
    def _calculate_competition_score(self, problem: str, solution: str) -> float:
        """è®¡ç®—ç«èµ›ç›¸å…³æ€§å¾—åˆ† (0-1)"""
        score = 0.0
        
        # ç«èµ›å…³é”®è¯
        competition_indicators = {
            'prove': 0.3, 'find all': 0.25, 'determine': 0.2, 'show that': 0.25,
            'inequality': 0.2, 'polynomial': 0.15, 'optimization': 0.2,
            'olympiad': 0.4, 'competition': 0.3, 'contest': 0.3,
            'integer': 0.15, 'prime': 0.2, 'modular': 0.15,
            'triangle': 0.1, 'circle': 0.1, 'geometry': 0.15,
            'combinatorics': 0.2, 'permutation': 0.15, 'combination': 0.15
        }
        
        text = (problem + " " + solution).lower()
        for keyword, weight in competition_indicators.items():
            if keyword in text:
                score += weight
        
        # æ•°å­¦å¤æ‚æ€§æŒ‡æ ‡
        if re.search(r'x\^[3-9]|x\^\{[0-9]+\}', text):  # é«˜æ¬¡å¤šé¡¹å¼
            score += 0.15
        if len(re.findall(r'[a-z]\s*=\s*[^,\s]+', text)) > 2:  # å¤šå˜é‡
            score += 0.1
        if 'theorem' in text or 'lemma' in text:
            score += 0.2
        
        return min(score, 1.0)
    
    def _assess_difficulty_level(self, problem: str, solution: str) -> str:
        """è¯„ä¼°é—®é¢˜éš¾åº¦çº§åˆ«"""
        text = (problem + " " + solution).lower()
        
        # é«˜çº§æŒ‡æ ‡
        advanced_indicators = ['olympiad', 'contest', 'prove', 'lemma', 'theorem']
        if any(indicator in text for indicator in advanced_indicators):
            if 'olympiad' in text or 'usamo' in text or 'imo' in text:
                return 'olympiad'
            return 'advanced'
        
        # ä¸­çº§æŒ‡æ ‡
        intermediate_indicators = ['polynomial', 'inequality', 'optimization', 'calculus']
        if any(indicator in text for indicator in intermediate_indicators):
            return 'intermediate'
        
        # æ£€æŸ¥è§£ç­”å¤æ‚æ€§
        solution_lines = solution.split('\n')
        if len(solution_lines) > 5:  # å¤šæ­¥éª¤è§£ç­”
            return 'intermediate'
        
        return 'basic'
    
    def _extract_detailed_knowledge_points(self, problem_text: str) -> List[str]:
        """æå–è¯¦ç»†çŸ¥è¯†ç‚¹ï¼ˆç«èµ›å¯¼å‘ï¼‰"""
        knowledge_patterns = {
            'Algebra': {
                'Polynomial': ['polynomial', 'degree', 'root', 'coefficient'],
                'Equation_Solving': ['equation', 'solve', 'roots', 'quadratic'],
                'Inequality': ['inequality', 'greater', 'less', 'maximum', 'minimum'],
                'Function': ['function', 'domain', 'range', 'inverse']
            },
            'Number_Theory': {
                'Prime_Numbers': ['prime', 'composite', 'factorization'],
                'Modular_Arithmetic': ['modular', 'remainder', 'congruent', 'mod'],
                'Divisibility': ['divisible', 'gcd', 'lcm', 'factor'],
                'Integer_Properties': ['integer', 'odd', 'even', 'perfect square']
            },
            'Geometry': {
                'Triangle_Geometry': ['triangle', 'angle', 'side', 'area'],
                'Circle_Geometry': ['circle', 'radius', 'diameter', 'circumference'],
                'Coordinate_Geometry': ['coordinate', 'plane', 'distance', 'slope'],
                'Solid_Geometry': ['volume', 'surface area', 'sphere', 'cube']
            },
            'Combinatorics': {
                'Counting': ['permutation', 'combination', 'counting', 'arrange'],
                'Probability': ['probability', 'random', 'expected value', 'variance'],
                'Graph_Theory': ['graph', 'vertex', 'edge', 'tree']
            },
            'Calculus': {
                'Differentiation': ['derivative', 'differentiate', 'rate of change'],
                'Integration': ['integral', 'integrate', 'area under curve'],
                'Optimization': ['maximum', 'minimum', 'critical point', 'optimize']
            }
        }
        
        found_points = []
        problem_lower = problem_text.lower()
        
        for category, subcategories in knowledge_patterns.items():
            for subcategory, keywords in subcategories.items():
                for keyword in keywords:
                    if keyword in problem_lower:
                        found_points.append(f"{category}:{subcategory}")
                        break
        
        return found_points if found_points else ['Basic_Math:Arithmetic']
    
    def _calculate_quality_score(self, problem: str, solution: str) -> float:
        """è®¡ç®—é—®é¢˜è´¨é‡åˆ†æ•°ï¼ˆç”¨äºGRPOè®­ç»ƒï¼‰"""
        score = 0.0
        
        # æ¸…æ™°åº¦åˆ†æ•°ï¼ˆåŸºäºé•¿åº¦å’Œç»“æ„ï¼‰
        problem_length = len(problem)
        if 50 <= problem_length <= 300:  # æœ€ä½³é•¿åº¦èŒƒå›´
            score += 0.25
        elif problem_length < 50:
            score += 0.1  # å¤ªçŸ­
        else:
            score += 0.15  # å¤ªé•¿
        
        # è§£ç­”å®Œæ•´æ€§
        solution_length = len(solution)
        if solution_length > 100:  # å……å®çš„è§£ç­”
            score += 0.25
        
        # æ•°å­¦ä¸¥è°¨æ€§æŒ‡æ ‡
        rigor_indicators = ['therefore', 'thus', 'hence', 'proof', 'qed', 'solution:']
        rigor_count = sum(1 for indicator in rigor_indicators if indicator.lower() in solution.lower())
        score += min(rigor_count * 0.1, 0.3)
        
        # æ–°é¢–æ€§ï¼ˆé¿å…å¸¸è§æ¨¡æ¿ï¼‰
        common_templates = ['find x', 'solve for', 'what is']
        template_penalty = sum(0.05 for template in common_templates if template in problem.lower())
        score -= template_penalty
        
        return max(0.0, min(score, 1.0))
    
    def create_grpo_training_dataset(self, num_examples: int = 1000) -> List[Dict]:
        """åˆ›å»ºGRPOä¼˜åŒ–çš„è®­ç»ƒæ•°æ®é›†ï¼ŒåŒ…å«å¥–åŠ±ä¿¡å·"""
        print(f"ğŸ”„ åˆ›å»ºGRPOè®­ç»ƒæ•°æ®é›†ï¼ŒåŒ…å« {num_examples} ä¸ªæ ·ä¾‹...")
        
        if not self.competition_problems:
            print("âŒ æ— ç«èµ›é—®é¢˜å¯ç”¨ã€‚è¯·å…ˆè¿è¡Œ load_real_datasets()")
            return []
        
        grpo_examples = []
        
        # è·¨éš¾åº¦çº§åˆ«é‡‡æ ·é—®é¢˜
        for difficulty_level in ['basic', 'intermediate', 'advanced', 'olympiad']:
            level_problems = self.difficulty_categories[difficulty_level]
            if not level_problems:
                continue
            
            # è®¡ç®—æ¯ä¸ªçº§åˆ«çš„æ ·ä¾‹æ•°é‡
            level_count = min(len(level_problems), num_examples // 4)
            selected_problems = random.sample(level_problems, level_count)
            
            for problem_data in selected_problems:
                # åˆ›å»ºé—®é¢˜ç”Ÿæˆæ ·ä¾‹
                generation_example = {
                    'conversations': [
                        {
                            'role': 'user',
                            'content': f"ç”Ÿæˆä¸€ä¸ª{difficulty_level}çº§åˆ«çš„ç«èµ›æ•°å­¦é—®é¢˜ï¼Œç±»å‹ä¸º{problem_data['knowledge_points'][0] if problem_data['knowledge_points'] else 'algebra'}:"
                        },
                        {
                            'role': 'assistant',
                            'content': f"{problem_data['problem']}\n\nè§£ç­”: {problem_data['solution']}"
                        }
                    ],
                    'metadata': {
                        'difficulty_level': difficulty_level,
                        'knowledge_points': problem_data['knowledge_points'],
                        'quality_score': problem_data['quality_score'],
                        'competition_score': problem_data['competition_score'],
                        'reward_signals': self._generate_reward_signals(problem_data)
                    }
                }
                
                grpo_examples.append(generation_example)
                
                # åˆ›å»ºå˜åˆ†æ ·ä¾‹
                variation_examples = self._create_variation_examples(problem_data)
                grpo_examples.extend(variation_examples)
        
        print(f"âœ… åˆ›å»º {len(grpo_examples)} ä¸ªGRPOè®­ç»ƒæ ·ä¾‹")
        return grpo_examples
    
    def _generate_reward_signals(self, problem_data: Dict) -> Dict:
        """ç”ŸæˆGRPOè®­ç»ƒçš„å¥–åŠ±ä¿¡å·"""
        return {
            'difficulty_reward': self._difficulty_reward(problem_data['difficulty_level']),
            'novelty_reward': problem_data['quality_score'],
            'rigor_reward': min(len(problem_data['solution']) / 200, 1.0),
            'diversity_reward': len(problem_data['knowledge_points']) / 5
        }
    
    def _difficulty_reward(self, difficulty_level: str) -> float:
        """è®¡ç®—åŸºäºéš¾åº¦çš„å¥–åŠ±"""
        difficulty_scores = {
            'basic': 0.3,
            'intermediate': 0.6,
            'advanced': 0.8,
            'olympiad': 1.0
        }
        return difficulty_scores.get(difficulty_level, 0.5)
    
    def _create_variation_examples(self, problem_data: Dict) -> List[Dict]:
        """åˆ›å»ºå˜åˆ†ç”Ÿæˆæ ·ä¾‹ï¼ˆç”¨äºåè°ƒè®­ç»ƒï¼‰"""
        variations = []
        
        original_problem = problem_data['problem']
        original_solution = problem_data['solution']
        
        # ç±»å‹1ï¼šå‚æ•°å˜åˆ†
        param_variation = self._generate_parameter_variation(original_problem)
        if param_variation != original_problem:
            variations.append({
                'conversations': [
                    {
                        'role': 'user',
                        'content': f"ä¸ºæ­¤é—®é¢˜ç”Ÿæˆå‚æ•°å˜åˆ†: {original_problem}"
                    },
                    {
                        'role': 'assistant',
                        'content': f"{param_variation}\n\nè§£ç­”: {self._adapt_solution_for_variation(original_solution, 'parameter')}"
                    }
                ],
                'metadata': {
                    'variation_type': 'parameter',
                    'original_quality': problem_data['quality_score'],
                    'difficulty_level': problem_data['difficulty_level']
                }
            })
        
        # ç±»å‹2ï¼šè¯­å¢ƒå˜åˆ†
        context_variation = self._generate_context_variation(original_problem)
        if context_variation != original_problem:
            variations.append({
                'conversations': [
                    {
                        'role': 'user',
                        'content': f"ä¸ºæ­¤é—®é¢˜ç”Ÿæˆè¯­å¢ƒå˜åˆ†: {original_problem}"
                    },
                    {
                        'role': 'assistant',
                        'content': f"{context_variation}\n\nè§£ç­”: {self._adapt_solution_for_variation(original_solution, 'context')}"
                    }
                ],
                'metadata': {
                    'variation_type': 'context',
                    'original_quality': problem_data['quality_score'],
                    'difficulty_level': problem_data['difficulty_level']
                }
            })
        
        return variations
    
    def _generate_parameter_variation(self, original_problem: str) -> str:
        """ç”ŸæˆåŸºäºå‚æ•°çš„å˜åˆ†"""
        # æå–å’Œä¿®æ”¹æ•°å€¼å‚æ•°
        numbers = re.findall(r'\b\d+\.?\d*\b', original_problem)
        varied_problem = original_problem
        
        for num in numbers[:2]:  # ä¿®æ”¹å‰2ä¸ªæ•°å­—
            try:
                old_val = float(num)
                if old_val <= 20:
                    new_val = random.randint(1, 25)
                else:
                    new_val = int(old_val * random.uniform(0.7, 1.5))
                
                varied_problem = varied_problem.replace(num, str(new_val), 1)
            except:
                continue
        
        return varied_problem
    
    def _generate_context_variation(self, original_problem: str) -> str:
        """ç”ŸæˆåŸºäºè¯­å¢ƒçš„å˜åˆ†"""
        # ç®€å•è¯­å¢ƒè½¬æ¢
        context_mappings = {
            'triangle': 'quadrilateral',
            'circle': 'ellipse', 
            'square': 'rectangle',
            'find': 'determine',
            'calculate': 'compute',
            'prove': 'show',
            'x': 'y',
            'function f': 'function g'
        }
        
        varied_problem = original_problem
        for old_term, new_term in context_mappings.items():
            if old_term in varied_problem.lower():
                varied_problem = re.sub(
                    r'\b' + re.escape(old_term) + r'\b',
                    new_term,
                    varied_problem,
                    count=1,
                    flags=re.IGNORECASE
                )
                break
        
        return varied_problem
    
    def _adapt_solution_for_variation(self, original_solution: str, variation_type: str) -> str:
        """ä¸ºå˜åˆ†é€‚é…è§£ç­”"""
        if variation_type == 'parameter':
            return "è§£ç­”æ–¹æ³•ä¸åŸé—®é¢˜ç›¸åŒï¼Œæ›´æ–°äº†æ•°å€¼å‚æ•°ã€‚"
        elif variation_type == 'context':
            return "è§£ç­”æ–¹æ³•ä¿æŒä¸€è‡´ï¼Œé€‚é…äº†æ–°çš„è¯­å¢ƒã€‚"
        return original_solution[:100] + "..."
    
    def create_deepseek_integration_dataset(self) -> List[Dict]:
        """åˆ›å»ºDeepSeek-R1æ•™å¸ˆé›†æˆæ•°æ®é›†"""
        print("ğŸ”„ åˆ›å»ºDeepSeeké›†æˆæ•°æ®é›†...")
        
        integration_examples = []
        
        # é—®é¢˜è¯„ä¼°æ ·ä¾‹
        for problem_data in self.competition_problems[:50]:  # é‡‡æ ·å­é›†
            integration_examples.append({
                'task_type': 'evaluation',
                'input': problem_data['problem'],
                'expected_output': {
                    'difficulty': problem_data['difficulty_level'],
                    'quality_score': problem_data['quality_score'],
                    'knowledge_points': problem_data['knowledge_points']
                }
            })
        
        # é—®é¢˜æ”¹è¿›æ ·ä¾‹
        low_quality_problems = [p for p in self.competition_problems if p['quality_score'] < 0.5]
        for problem_data in low_quality_problems[:20]:
            integration_examples.append({
                'task_type': 'improvement',
                'input': {
                    'problem': problem_data['problem'],
                    'feedback': 'æé«˜æ¸…æ™°åº¦å’Œæ•°å­¦ä¸¥è°¨æ€§'
                },
                'expected_improvement_areas': ['clarity', 'rigor', 'completeness']
            })
        
        print(f"âœ… åˆ›å»º {len(integration_examples)} ä¸ªDeepSeeké›†æˆæ ·ä¾‹")
        return integration_examples
    
    def prepare_unsloth_training_dataset(self, tokenizer, chat_percentage: float = 0.25) -> Dataset:
        """å¢å¼ºç‰ˆunslothè®­ç»ƒæ•°æ®é›†å‡†å¤‡"""
        print("ğŸ”„ å‡†å¤‡å¢å¼ºç‰ˆunslothè®­ç»ƒæ•°æ®é›†...")
        
        # è®¾ç½®tokenizer
        self.tokenizer = tokenizer
        
        # åŠ è½½å’Œå¤„ç†æ•°æ®é›†
        self.load_real_datasets()  # è¿™ä¼šåœ¨å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        
        # ä½¿ç”¨å¢å¼ºçš„ç«èµ›èšç„¦å¤„ç†
        if not self._process_enhanced_reasoning_data():
            raise RuntimeError("âŒ æ¨ç†æ•°æ®å¤„ç†å¤±è´¥")
        
        if not self.process_non_reasoning_data():
            raise RuntimeError("âŒ éæ¨ç†æ•°æ®å¤„ç†å¤±è´¥")
        
        # åˆ›å»ºå¢å¼ºçš„ç»„åˆæ•°æ®é›†
        combined_dataset = self._create_enhanced_combined_dataset(chat_percentage)
        
        print("âœ… å¢å¼ºç‰ˆunslothè®­ç»ƒæ•°æ®é›†å‡†å¤‡å®Œæˆ!")
        return combined_dataset
    
    def _process_enhanced_reasoning_data(self):
        """å¤„ç†æ¨ç†æ•°æ®ï¼ˆç«èµ›èšç„¦ï¼‰"""
        print("ğŸ”„ å¤„ç†æ¨ç†æ•°æ®ï¼ˆç«èµ›å¢å¼ºï¼‰...")
        
        enhanced_conversations = []
        
        # ä¼˜å…ˆç«èµ›é—®é¢˜
        for problem_data in self.competition_problems:
            conversation = [
                {"role": "user", "content": f"ç”Ÿæˆä¸€ä¸ª{problem_data['difficulty_level']}çº§åˆ«çš„ç«èµ›é—®é¢˜:"},
                {"role": "assistant", "content": f"{problem_data['problem']}\n\nè§£ç­”: {problem_data['solution']}"}
            ]
            enhanced_conversations.append(conversation)
        
        # æ·»åŠ å‰©ä½™é—®é¢˜
        remaining_count = len(self.reasoning_dataset) - len(self.competition_problems)
        if remaining_count > 0:
            for i, item in enumerate(self.reasoning_dataset):
                if i >= len(self.competition_problems):
                    if 'problem' in item and 'generated_solution' in item:
                        conversation = [
                            {"role": "user", "content": item['problem']},
                            {"role": "assistant", "content": item['generated_solution']}
                        ]
                        enhanced_conversations.append(conversation)
        
        # åº”ç”¨èŠå¤©æ¨¡æ¿
        self.reasoning_conversations = self.tokenizer.apply_chat_template(
            enhanced_conversations,
            tokenize = False,
        )
        
        print(f"âœ… å¤„ç† {len(self.reasoning_conversations)} ä¸ªå¢å¼ºæ¨ç†å¯¹è¯")
        return True
    
    def _create_enhanced_combined_dataset(self, chat_percentage: float) -> Dataset:
        """åˆ›å»ºå¢å¼ºçš„ç»„åˆæ•°æ®é›†ï¼ˆè´¨é‡ä¼˜å…ˆï¼‰"""
        print(f"ğŸ”„ åˆ›å»ºå¢å¼ºç»„åˆæ•°æ®é›†ï¼ŒåŒ…å«{chat_percentage*100}%èŠå¤©æ•°æ®...")
        
        # é‡‡æ ·éæ¨ç†æ•°æ®
        non_reasoning_subset = pd.Series(self.non_reasoning_conversations)
        non_reasoning_subset = non_reasoning_subset.sample(
            int(len(self.reasoning_conversations)*(chat_percentage/(1 - chat_percentage))),
            random_state = 2407,
        )
        
        # åŸºäºè´¨é‡çš„ç»„åˆæ’åº
        reasoning_series = pd.Series(self.reasoning_conversations)
        
        # å¦‚æœæœ‰ç«èµ›é—®é¢˜ï¼Œä¼˜å…ˆé«˜è´¨é‡æ ·ä¾‹
        if self.competition_problems:
            # æŒ‰è´¨é‡åˆ†æ•°æ’åºï¼Œé«˜è´¨é‡æ ·ä¾‹ä¼˜å…ˆ
            quality_sorted_indices = sorted(
                range(min(len(self.competition_problems), len(reasoning_series))),
                key=lambda i: self.competition_problems[i]['quality_score'] if i < len(self.competition_problems) else 0,
                reverse=True
            )
            
            # é‡æ–°æ’åºæ¨ç†å¯¹è¯ï¼Œä¼˜å…ˆé«˜è´¨é‡é—®é¢˜
            high_quality_conversations = [self.reasoning_conversations[i] for i in quality_sorted_indices[:len(quality_sorted_indices)//2]]
            remaining_conversations = [conv for i, conv in enumerate(self.reasoning_conversations) if i not in quality_sorted_indices[:len(quality_sorted_indices)//2]]
            
            reordered_reasoning = high_quality_conversations + remaining_conversations
            reasoning_series = pd.Series(reordered_reasoning)
        
        # ç»„åˆæ•°æ®é›†
        data = pd.concat([reasoning_series, non_reasoning_subset])
        data.name = "text"
        
        # åˆ›å»ºæœ€ç»ˆæ•°æ®é›†
        self.combined_dataset = Dataset.from_pandas(pd.DataFrame(data))
        self.combined_dataset = self.combined_dataset.shuffle(seed = 3407)
        
        print(f"âœ… å¢å¼ºç»„åˆæ•°æ®é›†åˆ›å»º: {len(self.combined_dataset)} æ€»æ¡ç›®")
        print(f"ğŸ“Š ç«èµ›é—®é¢˜ä¼˜å…ˆ: {len(self.competition_problems) if self.competition_problems else 0}")
        
        return self.combined_dataset
    
    def process_non_reasoning_data(self):
        """å¤„ç†éæ¨ç†æ•°æ®é›† - éµå¾ªå‚è€ƒè„šæœ¬"""
        if self.non_reasoning_dataset is None or self.tokenizer is None:
            print("âŒ è¯·å…ˆåŠ è½½æ•°æ®é›†å¹¶è®¾ç½®tokenizer")
            return None
            
        print("ğŸ”„ è½¬æ¢éæ¨ç†æ•°æ®é›†ä¸ºå¯¹è¯æ ¼å¼...")
        
        # ä½¿ç”¨Unslothçš„standardize_sharegptå‡½æ•°
        dataset = standardize_sharegpt(self.non_reasoning_dataset)
        
        self.non_reasoning_conversations = self.tokenizer.apply_chat_template(
            dataset["conversations"],
            tokenize = False,
        )
        
        print(f"âœ… å¤„ç† {len(self.non_reasoning_conversations)} ä¸ªéæ¨ç†å¯¹è¯")
        return self.non_reasoning_conversations
    
    def get_training_statistics(self) -> Dict:
        """è·å–ç»¼åˆè®­ç»ƒç»Ÿè®¡"""
        stats = {
            'total_problems': len(self.reasoning_dataset) if self.reasoning_dataset else 0,
            'competition_problems': len(self.competition_problems),
            'difficulty_distribution': {level: len(problems) for level, problems in self.difficulty_categories.items()},
            'average_quality_score': np.mean([p['quality_score'] for p in self.competition_problems]) if self.competition_problems else 0,
            'knowledge_point_coverage': len(set().union(*[p['knowledge_points'] for p in self.competition_problems])) if self.competition_problems else 0
        }
        
        return stats
    
    def create_grpo_variation_training_data(self) -> List[Dict]:
        """ä¸ºStage 2 GRPOåˆ›å»ºå˜åˆ†è®­ç»ƒæ•°æ®"""
        print("ğŸ”„ åˆ›å»ºGRPOå˜åˆ†è®­ç»ƒæ•°æ®...")
        
        # å¦‚æœè¿˜æ²¡æœ‰åŠ è½½æ•°æ®é›†ï¼Œå…ˆåŠ è½½
        if not self.competition_problems:
            print("ğŸ“Š æ•°æ®é›†å°šæœªåŠ è½½ï¼Œå¼€å§‹åŠ è½½çœŸå®æ•°æ®é›†...")
            self.load_real_datasets()  # è¿™ä¼šåœ¨å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
            
        if not self.competition_problems:
            raise RuntimeError("âŒ åŠ è½½æ•°æ®é›†åä»æ— ç«èµ›é—®é¢˜å¯ç”¨äºGRPOè®­ç»ƒã€‚")
        
        # ä½¿ç”¨ç°æœ‰æ–¹æ³•åˆ›å»ºGRPOæ•°æ®é›†
        grpo_data = self.create_grpo_training_dataset(num_examples=500)
        
        print(f"âœ… åˆ›å»º {len(grpo_data)} ä¸ªGRPOå˜åˆ†è®­ç»ƒæ ·ä¾‹")
        return grpo_data
    
    # ==================== æ–°å¢ï¼šä¸‰é˜¶æ®µè®­ç»ƒä¸“ç”¨æ–¹æ³• ====================
    
    def create_stage1_basic_dataset(self, tokenizer) -> Dataset:
        """ä¸ºStage 1åŸºç¡€é¢„è®­ç»ƒåˆ›å»ºä¸“é—¨æ•°æ®é›†"""
        print("ğŸ”„ åˆ›å»ºStage 1åŸºç¡€é¢„è®­ç»ƒæ•°æ®é›†...")
        
        # ä½¿ç”¨é«˜è´¨é‡ç«èµ›é—®é¢˜ + å¹³è¡¡çš„å¯¹è¯æ•°æ®
        return self.prepare_unsloth_training_dataset(tokenizer, chat_percentage=0.25)
    
    def create_stage2_grpo_dataset(self, num_examples: int = 500) -> List[Dict]:
        """ä¸ºStage 2 GRPOè®­ç»ƒåˆ›å»ºåˆ†ç»„æ¯”è¾ƒæ•°æ®é›†"""
        print(f"ğŸ”„ åˆ›å»ºStage 2 GRPOè®­ç»ƒæ•°æ®é›†ï¼ŒåŒ…å«{num_examples}ä¸ªåˆ†ç»„æ¯”è¾ƒæ ·ä¾‹...")
        
        grpo_groups = []
        
        # ä¸ºæ¯ä¸ªéš¾åº¦çº§åˆ«åˆ›å»ºé—®é¢˜ç»„
        for difficulty_level in ['basic', 'intermediate', 'advanced', 'olympiad']:
            level_problems = self.difficulty_categories[difficulty_level]
            if len(level_problems) < 4:  # éœ€è¦è‡³å°‘4ä¸ªé—®é¢˜å½¢æˆç»„
                continue
            
            # åˆ›å»ºé—®é¢˜ç»„ï¼ˆæ¯ç»„8ä¸ªé—®é¢˜ç”¨äºæ¯”è¾ƒï¼‰
            group_size = 8
            num_groups = min(len(level_problems) // group_size, num_examples // 4)
            
            for group_idx in range(num_groups):
                start_idx = group_idx * group_size
                group_problems = level_problems[start_idx:start_idx + group_size]
                
                # æŒ‰è´¨é‡åˆ†æ•°æ’åºï¼Œåˆ›å»ºå¥–åŠ±æ¢¯åº¦
                group_problems.sort(key=lambda x: x['quality_score'], reverse=True)
                
                grpo_group = {
                    'group_id': f"{difficulty_level}_group_{group_idx}",
                    'difficulty_level': difficulty_level,
                    'problems': [],
                    'rewards': [],
                    'prompt': f"ç”Ÿæˆä¸€ä¸ª{difficulty_level}çº§åˆ«çš„é«˜è´¨é‡ç«èµ›æ•°å­¦é—®é¢˜ï¼š"
                }
                
                for i, problem_data in enumerate(group_problems):
                    grpo_group['problems'].append({
                        'problem': problem_data['problem'],
                        'solution': problem_data['solution'],
                        'quality_score': problem_data['quality_score']
                    })
                    
                    # è®¡ç®—GRPOå¥–åŠ±ï¼ˆè´¨é‡åˆ†æ•° + æ’åå¥–åŠ±ï¼‰
                    rank_reward = (len(group_problems) - i) / len(group_problems)
                    total_reward = problem_data['quality_score'] * 0.7 + rank_reward * 0.3
                    grpo_group['rewards'].append(total_reward)
                
                grpo_groups.append(grpo_group)
        
        print(f"âœ… åˆ›å»º{len(grpo_groups)}ä¸ªGRPOè®­ç»ƒç»„")
        return grpo_groups
    
    def create_stage3_distillation_dataset(self, num_examples: int = 200) -> List[Dict]:
        """ä¸ºStage 3çŸ¥è¯†è’¸é¦åˆ›å»ºteacher-studentå¯¹æ¯”æ•°æ®é›†"""
        print(f"ğŸ”„ åˆ›å»ºStage 3çŸ¥è¯†è’¸é¦æ•°æ®é›†ï¼ŒåŒ…å«{num_examples}ä¸ªteacher-studentæ ·ä¾‹...")
        
        distillation_examples = []
        
        # é€‰æ‹©æœ€é«˜è´¨é‡çš„ç«èµ›é—®é¢˜ç”¨äºè’¸é¦
        high_quality_problems = [p for p in self.competition_problems if p['quality_score'] > 0.7]
        high_quality_problems.sort(key=lambda x: x['quality_score'], reverse=True)
        
        selected_problems = high_quality_problems[:num_examples]
        
        for problem_data in selected_problems:
            # åˆ›å»ºè’¸é¦æ ·ä¾‹ï¼šå­¦ç”Ÿç”Ÿæˆ -> DeepSeekæ•™å¸ˆè¯„ä¼°/æ”¹è¿›
            distillation_example = {
                'student_input': {
                    'prompt': f"ç”Ÿæˆä¸€ä¸ª{problem_data['difficulty_level']}çº§åˆ«çš„ç«èµ›é—®é¢˜ï¼Œè¦æ±‚ï¼š",
                    'requirements': [
                        'æ•°å­¦ä¸¥è°¨æ€§é«˜',
                        'éš¾åº¦é€‚ä¸­æœ‰æŒ‘æˆ˜æ€§', 
                        'è§£ç­”æ­¥éª¤æ¸…æ™°',
                        'å…·æœ‰æ•™è‚²ä»·å€¼'
                    ]
                },
                'student_output': {
                    'problem': problem_data['problem'],
                    'solution': problem_data['solution']
                },
                'teacher_feedback': {
                    'evaluation_dimensions': {
                        'difficulty': self._difficulty_reward(problem_data['difficulty_level']),
                        'novelty': problem_data['quality_score'],
                        'rigor': min(len(problem_data['solution']) / 200, 1.0),
                        'diversity': len(problem_data['knowledge_points']) / 5
                    },
                    'improvement_suggestions': self._generate_improvement_suggestions(problem_data),
                    'overall_score': problem_data['quality_score']
                },
                'knowledge_points': problem_data['knowledge_points'],
                'difficulty_level': problem_data['difficulty_level']
            }
            
            distillation_examples.append(distillation_example)
        
        print(f"âœ… åˆ›å»º{len(distillation_examples)}ä¸ªè’¸é¦è®­ç»ƒæ ·ä¾‹")
        return distillation_examples
    
    def _generate_improvement_suggestions(self, problem_data: Dict) -> List[str]:
        """æ ¹æ®é—®é¢˜æ•°æ®ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []
        
        quality_score = problem_data['quality_score']
        solution_length = len(problem_data['solution'])
        
        if quality_score < 0.6:
            suggestions.append("æé«˜é—®é¢˜çš„æ•°å­¦ä¸¥è°¨æ€§å’Œæ¸…æ™°åº¦")
        
        if solution_length < 100:
            suggestions.append("æä¾›æ›´è¯¦ç»†çš„è§£ç­”æ­¥éª¤å’Œæ¨ç†è¿‡ç¨‹")
        
        if len(problem_data['knowledge_points']) < 2:
            suggestions.append("å¢åŠ é—®é¢˜çš„ç»¼åˆæ€§ï¼Œèåˆå¤šä¸ªçŸ¥è¯†ç‚¹")
        
        if problem_data['difficulty_level'] == 'basic':
            suggestions.append("é€‚å½“æå‡é—®é¢˜éš¾åº¦ï¼Œå¢åŠ æŒ‘æˆ˜æ€§")
        
        if not suggestions:
            suggestions.append("ä¿æŒå½“å‰é«˜è´¨é‡æ°´å‡†ï¼Œç»§ç»­å‘æŒ¥åˆ›æ–°æ€§")
        
        return suggestions
    
    def create_coordinated_variation_dataset(self, original_problems: List[Dict], num_variations_per_problem: int = 3) -> List[Dict]:
        """åˆ›å»ºåè°ƒå˜åˆ†è®­ç»ƒæ•°æ®é›†ï¼ˆæ”¯æŒå˜åˆ†ç”Ÿæˆè®­ç»ƒï¼‰"""
        print(f"ğŸ”„ åˆ›å»ºåè°ƒå˜åˆ†è®­ç»ƒæ•°æ®é›†...")
        
        variation_dataset = []
        
        for problem_data in original_problems:
            original_problem = problem_data['problem']
            
            # ç”Ÿæˆå¤šç§ç±»å‹çš„å˜åˆ†
            variation_types = ['parameter', 'context', 'difficulty', 'knowledge_point']
            
            for variation_type in variation_types:
                for i in range(num_variations_per_problem):
                    if variation_type == 'parameter':
                        varied_problem = self._generate_parameter_variation(original_problem)
                    elif variation_type == 'context':
                        varied_problem = self._generate_context_variation(original_problem)
                    elif variation_type == 'difficulty':
                        varied_problem = self._generate_difficulty_variation(original_problem, problem_data['difficulty_level'])
                    elif variation_type == 'knowledge_point':
                        varied_problem = self._generate_knowledge_variation(original_problem, problem_data['knowledge_points'])
                    else:
                        continue
                    
                    if varied_problem != original_problem:
                        variation_example = {
                            'original': {
                                'problem': original_problem,
                                'solution': problem_data['solution'],
                                'quality_score': problem_data['quality_score']
                            },
                            'variation': {
                                'problem': varied_problem,
                                'solution': self._adapt_solution_for_variation(problem_data['solution'], variation_type),
                                'variation_type': variation_type,
                                'variation_index': i
                            },
                            'training_prompt': f"ä¸ºåŸå§‹é—®é¢˜ç”Ÿæˆ{variation_type}ç±»å‹çš„å˜åˆ†ç‰ˆæœ¬",
                            'metadata': {
                                'difficulty_level': problem_data['difficulty_level'],
                                'knowledge_points': problem_data['knowledge_points']
                            }
                        }
                        
                        variation_dataset.append(variation_example)
        
        print(f"âœ… åˆ›å»º{len(variation_dataset)}ä¸ªåè°ƒå˜åˆ†è®­ç»ƒæ ·ä¾‹")
        return variation_dataset
    
    def _generate_difficulty_variation(self, original_problem: str, current_level: str) -> str:
        """ç”Ÿæˆéš¾åº¦å˜åˆ†"""
        # ç®€å•çš„éš¾åº¦è°ƒæ•´ç­–ç•¥
        if current_level == 'basic':
            # æå‡åˆ°intermediateï¼šæ·»åŠ å¤æ‚æ€§
            return original_problem.replace('find', 'prove and find').replace('calculate', 'derive and calculate')
        elif current_level == 'intermediate':
            # æå‡åˆ°advancedï¼šæ·»åŠ çº¦æŸæ¡ä»¶
            return original_problem + " Additionally, prove that your solution is unique."
        elif current_level == 'advanced':
            # æå‡åˆ°olympiadï¼šæ·»åŠ æ¨å¹¿
            return original_problem + " Generalize this result for the n-dimensional case."
        else:
            # olympiadä¿æŒåŸæ ·
            return original_problem
    
    def _generate_knowledge_variation(self, original_problem: str, knowledge_points: List[str]) -> str:
        """ç”ŸæˆçŸ¥è¯†ç‚¹å˜åˆ†"""
        # ç®€å•çš„çŸ¥è¯†ç‚¹è½¬æ¢
        knowledge_mappings = {
            'Algebra:Polynomial': 'Number_Theory:Prime_Numbers',
            'Geometry:Triangle_Geometry': 'Geometry:Circle_Geometry',
            'Calculus:Differentiation': 'Calculus:Integration',
            'Combinatorics:Counting': 'Combinatorics:Probability'
        }
        
        varied_problem = original_problem
        
        for kp in knowledge_points:
            if kp in knowledge_mappings:
                target_kp = knowledge_mappings[kp]
                # ç®€å•çš„å…³é”®è¯æ›¿æ¢
                if 'Triangle' in kp:
                    varied_problem = varied_problem.replace('triangle', 'circle').replace('angle', 'radius')
                elif 'Polynomial' in kp:
                    varied_problem = varied_problem.replace('polynomial', 'prime number').replace('degree', 'divisor')
                
                break
        
        return varied_problem
    
    def validate_dataset_quality(self, dataset_name: str, dataset: any) -> Dict:
        """éªŒè¯æ•°æ®é›†è´¨é‡"""
        print(f"ğŸ” éªŒè¯{dataset_name}æ•°æ®é›†è´¨é‡...")
        
        validation_report = {
            'dataset_name': dataset_name,
            'total_examples': 0,
            'quality_distribution': {},
            'difficulty_balance': {},
            'knowledge_coverage': set(),
            'potential_issues': []
        }
        
        if isinstance(dataset, list):
            validation_report['total_examples'] = len(dataset)
            
            # ç»Ÿè®¡è´¨é‡åˆ†å¸ƒ
            quality_scores = []
            difficulty_counts = {}
            
            for item in dataset:
                if isinstance(item, dict):
                    # æ£€æŸ¥GRPOæ•°æ®é›†
                    if 'problems' in item:
                        for problem in item['problems']:
                            if 'quality_score' in problem:
                                quality_scores.append(problem['quality_score'])
                    
                    # æ£€æŸ¥è’¸é¦æ•°æ®é›†
                    elif 'teacher_feedback' in item:
                        if 'overall_score' in item['teacher_feedback']:
                            quality_scores.append(item['teacher_feedback']['overall_score'])
                        if 'difficulty_level' in item:
                            difficulty_counts[item['difficulty_level']] = difficulty_counts.get(item['difficulty_level'], 0) + 1
                        if 'knowledge_points' in item:
                            validation_report['knowledge_coverage'].update(item['knowledge_points'])
            
            if quality_scores:
                validation_report['quality_distribution'] = {
                    'mean': np.mean(quality_scores),
                    'std': np.std(quality_scores),
                    'min': np.min(quality_scores),
                    'max': np.max(quality_scores)
                }
            
            validation_report['difficulty_balance'] = difficulty_counts
        
        # æ£€æŸ¥æ½œåœ¨é—®é¢˜
        if validation_report['total_examples'] < 50:
            validation_report['potential_issues'].append("æ•°æ®é›†è§„æ¨¡è¾ƒå°ï¼Œå»ºè®®å¢åŠ æ ·ä¾‹æ•°é‡")
        
        if len(validation_report['knowledge_coverage']) < 5:
            validation_report['potential_issues'].append("çŸ¥è¯†ç‚¹è¦†ç›–ä¸è¶³ï¼Œå»ºè®®å¢åŠ å¤šæ ·æ€§")
        
        print(f"âœ… {dataset_name}è´¨é‡éªŒè¯å®Œæˆ")
        return validation_report

# ==================== å…¼å®¹æ€§åŒ…è£…å™¨ ====================
class RealMathDataProcessor(EnhancedMathDataProcessor):
    """å…¼å®¹æ€§åŒ…è£…å™¨"""
    pass

# ==================== æ–°å¢ï¼šä¸‰é˜¶æ®µè®­ç»ƒä¸“ç”¨æ‰©å±•æ–¹æ³• ====================

def create_stage1_basic_dataset(processor: EnhancedMathDataProcessor, tokenizer) -> Dataset:
    """ä¸ºStage 1åŸºç¡€é¢„è®­ç»ƒåˆ›å»ºä¸“é—¨æ•°æ®é›†"""
    print("ğŸ”„ åˆ›å»ºStage 1åŸºç¡€é¢„è®­ç»ƒæ•°æ®é›†...")
    
    # ä½¿ç”¨é«˜è´¨é‡ç«èµ›é—®é¢˜ + å¹³è¡¡çš„å¯¹è¯æ•°æ®
    return processor.prepare_unsloth_training_dataset(tokenizer, chat_percentage=0.25)

def create_stage2_grpo_dataset(processor: EnhancedMathDataProcessor, num_examples: int = 500) -> List[Dict]:
    """ä¸ºStage 2 GRPOè®­ç»ƒåˆ›å»ºåˆ†ç»„æ¯”è¾ƒæ•°æ®é›†"""
    print(f"ğŸ”„ åˆ›å»ºStage 2 GRPOè®­ç»ƒæ•°æ®é›†ï¼ŒåŒ…å«{num_examples}ä¸ªåˆ†ç»„æ¯”è¾ƒæ ·ä¾‹...")
    
    grpo_groups = []
    
    # ä¸ºæ¯ä¸ªéš¾åº¦çº§åˆ«åˆ›å»ºé—®é¢˜ç»„
    for difficulty_level in ['basic', 'intermediate', 'advanced', 'olympiad']:
        level_problems = processor.difficulty_categories[difficulty_level]
        if len(level_problems) < 4:  # éœ€è¦è‡³å°‘4ä¸ªé—®é¢˜å½¢æˆç»„
            continue
        
        # åˆ›å»ºé—®é¢˜ç»„ï¼ˆæ¯ç»„8ä¸ªé—®é¢˜ç”¨äºæ¯”è¾ƒï¼‰
        group_size = 8
        num_groups = min(len(level_problems) // group_size, num_examples // 4)
        
        for group_idx in range(num_groups):
            start_idx = group_idx * group_size
            group_problems = level_problems[start_idx:start_idx + group_size]
            
            # æŒ‰è´¨é‡åˆ†æ•°æ’åºï¼Œåˆ›å»ºå¥–åŠ±æ¢¯åº¦
            group_problems.sort(key=lambda x: x['quality_score'], reverse=True)
            
            grpo_group = {
                'group_id': f"{difficulty_level}_group_{group_idx}",
                'difficulty_level': difficulty_level,
                'problems': [],
                'rewards': [],
                'prompt': f"ç”Ÿæˆä¸€ä¸ª{difficulty_level}çº§åˆ«çš„é«˜è´¨é‡ç«èµ›æ•°å­¦é—®é¢˜ï¼š"
            }
            
            for i, problem_data in enumerate(group_problems):
                grpo_group['problems'].append({
                    'problem': problem_data['problem'],
                    'solution': problem_data['solution'],
                    'quality_score': problem_data['quality_score']
                })
                
                # è®¡ç®—GRPOå¥–åŠ±ï¼ˆè´¨é‡åˆ†æ•° + æ’åå¥–åŠ±ï¼‰
                rank_reward = (len(group_problems) - i) / len(group_problems)
                total_reward = problem_data['quality_score'] * 0.7 + rank_reward * 0.3
                grpo_group['rewards'].append(total_reward)
            
            grpo_groups.append(grpo_group)
    
    print(f"âœ… åˆ›å»º{len(grpo_groups)}ä¸ªGRPOè®­ç»ƒç»„")
    return grpo_groups

def create_stage3_distillation_dataset(processor: EnhancedMathDataProcessor, num_examples: int = 200) -> List[Dict]:
    """ä¸ºStage 3çŸ¥è¯†è’¸é¦åˆ›å»ºteacher-studentå¯¹æ¯”æ•°æ®é›†"""
    print(f"ğŸ”„ åˆ›å»ºStage 3çŸ¥è¯†è’¸é¦æ•°æ®é›†ï¼ŒåŒ…å«{num_examples}ä¸ªteacher-studentæ ·ä¾‹...")
    
    distillation_examples = []
    
    # é€‰æ‹©æœ€é«˜è´¨é‡çš„ç«èµ›é—®é¢˜ç”¨äºè’¸é¦
    high_quality_problems = [p for p in processor.competition_problems if p['quality_score'] > 0.7]
    high_quality_problems.sort(key=lambda x: x['quality_score'], reverse=True)
    
    selected_problems = high_quality_problems[:num_examples]
    
    for problem_data in selected_problems:
        # åˆ›å»ºè’¸é¦æ ·ä¾‹ï¼šå­¦ç”Ÿç”Ÿæˆ -> DeepSeekæ•™å¸ˆè¯„ä¼°/æ”¹è¿›
        distillation_example = {
            'student_input': {
                'prompt': f"ç”Ÿæˆä¸€ä¸ª{problem_data['difficulty_level']}çº§åˆ«çš„ç«èµ›é—®é¢˜ï¼Œè¦æ±‚ï¼š",
                'requirements': [
                    'æ•°å­¦ä¸¥è°¨æ€§é«˜',
                    'éš¾åº¦é€‚ä¸­æœ‰æŒ‘æˆ˜æ€§', 
                    'è§£ç­”æ­¥éª¤æ¸…æ™°',
                    'å…·æœ‰æ•™è‚²ä»·å€¼'
                ]
            },
            'student_output': {
                'problem': problem_data['problem'],
                'solution': problem_data['solution']
            },
            'teacher_feedback': {
                'evaluation_dimensions': {
                    'difficulty': processor._difficulty_reward(problem_data['difficulty_level']),
                    'novelty': problem_data['quality_score'],
                    'rigor': min(len(problem_data['solution']) / 200, 1.0),
                    'diversity': len(problem_data['knowledge_points']) / 5
                },
                'improvement_suggestions': generate_improvement_suggestions(problem_data),
                'overall_score': problem_data['quality_score']
            },
            'knowledge_points': problem_data['knowledge_points'],
            'difficulty_level': problem_data['difficulty_level']
        }
        
        distillation_examples.append(distillation_example)
    
    print(f"âœ… åˆ›å»º{len(distillation_examples)}ä¸ªè’¸é¦è®­ç»ƒæ ·ä¾‹")
    return distillation_examples

def generate_improvement_suggestions(problem_data: Dict) -> List[str]:
    """æ ¹æ®é—®é¢˜æ•°æ®ç”Ÿæˆæ”¹è¿›å»ºè®®"""
    suggestions = []
    
    quality_score = problem_data['quality_score']
    solution_length = len(problem_data['solution'])
    
    if quality_score < 0.6:
        suggestions.append("æé«˜é—®é¢˜çš„æ•°å­¦ä¸¥è°¨æ€§å’Œæ¸…æ™°åº¦")
    
    if solution_length < 100:
        suggestions.append("æä¾›æ›´è¯¦ç»†çš„è§£ç­”æ­¥éª¤å’Œæ¨ç†è¿‡ç¨‹")
    
    if len(problem_data['knowledge_points']) < 2:
        suggestions.append("å¢åŠ é—®é¢˜çš„ç»¼åˆæ€§ï¼Œèåˆå¤šä¸ªçŸ¥è¯†ç‚¹")
    
    if problem_data['difficulty_level'] == 'basic':
        suggestions.append("é€‚å½“æå‡é—®é¢˜éš¾åº¦ï¼Œå¢åŠ æŒ‘æˆ˜æ€§")
    
    if not suggestions:
        suggestions.append("ä¿æŒå½“å‰é«˜è´¨é‡æ°´å‡†ï¼Œç»§ç»­å‘æŒ¥åˆ›æ–°æ€§")
    
    return suggestions

def create_coordinated_variation_dataset(processor: EnhancedMathDataProcessor, num_variations_per_problem: int = 3) -> List[Dict]:
    """åˆ›å»ºåè°ƒå˜åˆ†è®­ç»ƒæ•°æ®é›†ï¼ˆæ”¯æŒå˜åˆ†ç”Ÿæˆè®­ç»ƒï¼‰"""
    print(f"ğŸ”„ åˆ›å»ºåè°ƒå˜åˆ†è®­ç»ƒæ•°æ®é›†...")
    
    variation_dataset = []
    
    for problem_data in processor.competition_problems[:100]:  # ä½¿ç”¨å‰100ä¸ªé«˜è´¨é‡é—®é¢˜
        original_problem = problem_data['problem']
        
        # ç”Ÿæˆå¤šç§ç±»å‹çš„å˜åˆ†
        variation_types = ['parameter', 'context']
        
        for variation_type in variation_types:
            for i in range(num_variations_per_problem):
                if variation_type == 'parameter':
                    varied_problem = processor._generate_parameter_variation(original_problem)
                elif variation_type == 'context':
                    varied_problem = processor._generate_context_variation(original_problem)
                else:
                    continue
                
                if varied_problem != original_problem:
                    variation_example = {
                        'original': {
                            'problem': original_problem,
                            'solution': problem_data['solution'],
                            'quality_score': problem_data['quality_score']
                        },
                        'variation': {
                            'problem': varied_problem,
                            'solution': processor._adapt_solution_for_variation(problem_data['solution'], variation_type),
                            'variation_type': variation_type,
                            'variation_index': i
                        },
                        'training_prompt': f"ä¸ºåŸå§‹é—®é¢˜ç”Ÿæˆ{variation_type}ç±»å‹çš„å˜åˆ†ç‰ˆæœ¬",
                        'metadata': {
                            'difficulty_level': problem_data['difficulty_level'],
                            'knowledge_points': problem_data['knowledge_points']
                        }
                    }
                    
                    variation_dataset.append(variation_example)
    
    print(f"âœ… åˆ›å»º{len(variation_dataset)}ä¸ªåè°ƒå˜åˆ†è®­ç»ƒæ ·ä¾‹")
    return variation_dataset

def validate_dataset_quality(dataset_name: str, dataset: any) -> Dict:
    """éªŒè¯æ•°æ®é›†è´¨é‡"""
    print(f"ğŸ” éªŒè¯{dataset_name}æ•°æ®é›†è´¨é‡...")
    
    validation_report = {
        'dataset_name': dataset_name,
        'total_examples': 0,
        'quality_distribution': {},
        'difficulty_balance': {},
        'knowledge_coverage': set(),
        'potential_issues': []
    }
    
    if isinstance(dataset, list):
        validation_report['total_examples'] = len(dataset)
        
        # ç»Ÿè®¡è´¨é‡åˆ†å¸ƒ
        quality_scores = []
        difficulty_counts = {}
        
        for item in dataset:
            if isinstance(item, dict):
                # æ£€æŸ¥GRPOæ•°æ®é›†
                if 'problems' in item:
                    for problem in item['problems']:
                        if 'quality_score' in problem:
                            quality_scores.append(problem['quality_score'])
                
                # æ£€æŸ¥è’¸é¦æ•°æ®é›†
                elif 'teacher_feedback' in item:
                    if 'overall_score' in item['teacher_feedback']:
                        quality_scores.append(item['teacher_feedback']['overall_score'])
                    if 'difficulty_level' in item:
                        difficulty_counts[item['difficulty_level']] = difficulty_counts.get(item['difficulty_level'], 0) + 1
                    if 'knowledge_points' in item:
                        validation_report['knowledge_coverage'].update(item['knowledge_points'])
        
        if quality_scores:
            validation_report['quality_distribution'] = {
                'mean': np.mean(quality_scores),
                'std': np.std(quality_scores),
                'min': np.min(quality_scores),
                'max': np.max(quality_scores)
            }
        
        validation_report['difficulty_balance'] = difficulty_counts
    
    # æ£€æŸ¥æ½œåœ¨é—®é¢˜
    if validation_report['total_examples'] < 50:
        validation_report['potential_issues'].append("æ•°æ®é›†è§„æ¨¡è¾ƒå°ï¼Œå»ºè®®å¢åŠ æ ·ä¾‹æ•°é‡")
    
    if len(validation_report['knowledge_coverage']) < 5:
        validation_report['potential_issues'].append("çŸ¥è¯†ç‚¹è¦†ç›–ä¸è¶³ï¼Œå»ºè®®å¢åŠ å¤šæ ·æ€§")
    
    print(f"âœ… {dataset_name}è´¨é‡éªŒè¯å®Œæˆ")
    return validation_report

# ==================== æµ‹è¯•å‡½æ•° ====================
def test_enhanced_processor():
    """æµ‹è¯•å¢å¼ºå¤„ç†å™¨åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•å¢å¼ºæ•°å­¦æ•°æ®å¤„ç†å™¨")
    print("=" * 50)
    
    processor = EnhancedMathDataProcessor()
    
    # æµ‹è¯•å¢å¼ºæ•°æ®é›†åŠ è½½
    if not processor.load_real_datasets():
        print("âŒ å¢å¼ºæ•°æ®é›†åŠ è½½å¤±è´¥")
        return False
    
    # æµ‹è¯•GRPOæ•°æ®é›†åˆ›å»º
    grpo_dataset = processor.create_grpo_training_dataset(100)
    if grpo_dataset:
        print(f"âœ… GRPOæ•°æ®é›†åˆ›å»º: {len(grpo_dataset)} ä¸ªæ ·ä¾‹")
    
    # æµ‹è¯•DeepSeeké›†æˆæ•°æ®é›†
    deepseek_dataset = processor.create_deepseek_integration_dataset()
    if deepseek_dataset:
        print(f"âœ… DeepSeeké›†æˆæ•°æ®é›†åˆ›å»º: {len(deepseek_dataset)} ä¸ªæ ·ä¾‹")
    
    # æµ‹è¯•ä¸‰é˜¶æ®µè®­ç»ƒä¸“ç”¨æ•°æ®é›†
    if processor.competition_problems:
        # æµ‹è¯•Stage 2 GRPOæ•°æ®é›†
        stage2_dataset = create_stage2_grpo_dataset(processor, 100)
        print(f"âœ… Stage 2 GRPOæ•°æ®é›†: {len(stage2_dataset)} ä¸ªè®­ç»ƒç»„")
        
        # æµ‹è¯•Stage 3è’¸é¦æ•°æ®é›†
        stage3_dataset = create_stage3_distillation_dataset(processor, 50)
        print(f"âœ… Stage 3è’¸é¦æ•°æ®é›†: {len(stage3_dataset)} ä¸ªæ ·ä¾‹")
        
        # æµ‹è¯•åè°ƒå˜åˆ†æ•°æ®é›†
        variation_dataset = create_coordinated_variation_dataset(processor, 2)
        print(f"âœ… åè°ƒå˜åˆ†æ•°æ®é›†: {len(variation_dataset)} ä¸ªæ ·ä¾‹")
    
    # è·å–è®­ç»ƒç»Ÿè®¡
    stats = processor.get_training_statistics()
    print(f"\nğŸ“Š è®­ç»ƒç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    return True

if __name__ == "__main__":
    print("ğŸš€ å¢å¼ºç‰ˆçœŸå®æ•°å­¦æ•°æ®å¤„ç†å™¨ - Questions-Genä¼˜åŒ–")
    print("=" * 70)
    
    # æµ‹è¯•å¢å¼ºåŠŸèƒ½
    test_enhanced_processor() 