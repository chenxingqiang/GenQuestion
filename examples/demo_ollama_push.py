#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Questions-Gen Ollamaæ¨é€æ¼”ç¤º

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºå¦‚ä½•å°†å·²è®­ç»ƒçš„HuggingFaceæ¨¡å‹æ¨é€åˆ°Ollamaè¿›è¡Œæœ¬åœ°éƒ¨ç½²ã€‚
åŸºäºä½ å·²æœ‰çš„ä¸‰ä¸ªæ¨¡å‹ï¼š
- xingqiang/QuestionsGen-Qwen3-14b-stage1-fp-merged
- xingqiang/questions-gen-qwen3-14b-stage2-merged-16bit  
- xingqiang/questions-gen-qwen3-14b-final-merged-16bit
"""

import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, '.')

# å°è¯•å¯¼å…¥ï¼ˆå¯èƒ½éœ€è¦å®‰è£…ä¾èµ–ï¼‰
try:
    from questions_gen.utils.ollama_manager import OllamaManager
    from questions_gen.utils.hf_utils import HuggingFaceUtils
    print("âœ… Questions-GenåŒ…å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("ğŸ’¡ è¯·å…ˆå®‰è£…ä¾èµ–: pip install transformers huggingface_hub")
    sys.exit(1)


def main():
    """ä¸»æ¼”ç¤ºæµç¨‹"""
    print("ğŸ¦™ Questions-Gen Ollama æ¨é€æ¼”ç¤º")
    print("="*60)
    
    # 1. æ£€æŸ¥HuggingFaceæ¨¡å‹çŠ¶æ€
    print("ğŸ” Step 1: æ£€æŸ¥HuggingFaceæ¨¡å‹çŠ¶æ€")
    hf_utils = HuggingFaceUtils()
    
    print("éªŒè¯å·²è®­ç»ƒæ¨¡å‹...")
    verification = hf_utils.verify_models_exist()
    
    all_verified = all(verification.values())
    if all_verified:
        print("âœ… æ‰€æœ‰æ¨¡å‹éªŒè¯é€šè¿‡ï¼")
    else:
        print("âš ï¸ éƒ¨åˆ†æ¨¡å‹éªŒè¯å¤±è´¥")
        for stage, verified in verification.items():
            status = "âœ…" if verified else "âŒ"
            print(f"   {status} {stage} æ¨¡å‹")
    
    # 2. æ£€æŸ¥Ollamaç¯å¢ƒ
    print(f"\nğŸ”§ Step 2: æ£€æŸ¥Ollamaç¯å¢ƒ")
    ollama = OllamaManager()
    
    if not ollama.ollama_available:
        print("âŒ Ollamaæœªå®‰è£…æˆ–ä¸å¯ç”¨")
        print("ğŸ“‹ å®‰è£…è¯´æ˜:")
        print("   macOS: curl -fsSL https://ollama.ai/install.sh | sh")
        print("   Linux: curl -fsSL https://ollama.ai/install.sh | sh")
        print("   Windows: ä¸‹è½½å®‰è£…åŒ…ä» https://ollama.ai")
        print("\nğŸ’¡ å®‰è£…åè¯·é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
        return
    
    print("âœ… Ollamaç¯å¢ƒæ£€æŸ¥é€šè¿‡")
    
    # 3. æ£€æŸ¥ç°æœ‰æ¨¡å‹
    print(f"\nğŸ“‹ Step 3: æ£€æŸ¥ç°æœ‰Ollamaæ¨¡å‹")
    existing_models = ollama.list_questions_gen_models()
    
    if existing_models:
        print(f"å‘ç° {len(existing_models)} ä¸ªå·²å­˜åœ¨çš„Questions-Genæ¨¡å‹:")
        for model in existing_models:
            print(f"   âœ… {model}")
    else:
        print("ğŸ“­ æœªå‘ç°å·²å­˜åœ¨çš„Questions-Genæ¨¡å‹")
    
    # 4. æ¨é€æ¨¡å‹é€‰æ‹©
    print(f"\nğŸš€ Step 4: æ¨¡å‹æ¨é€é€‰é¡¹")
    print("å¯ç”¨çš„æ¨é€é€‰é¡¹:")
    print("1. æ¨é€æ‰€æœ‰æ¨¡å‹ (stage1, stage2, final)")
    print("2. æ¨é€å•ä¸ªæ¨¡å‹")
    print("3. ç”Ÿæˆä½¿ç”¨æŒ‡å—")
    print("4. æµ‹è¯•ç°æœ‰æ¨¡å‹")
    
    # æ¨é€æ¼”ç¤º
    if input("\næ˜¯å¦è¦æ¨é€æ‰€æœ‰æ¨¡å‹åˆ°Ollama? (y/N): ").lower().startswith('y'):
        print("\nğŸ”„ æ¨é€æ‰€æœ‰æ¨¡å‹åˆ°Ollama...")
        results = ollama.push_all_models(force=True)
        
        # æ˜¾ç¤ºç»“æœ
        successful = sum(results.values())
        total = len(results)
        print(f"\nğŸ“Š æ¨é€ç»“æœ: {successful}/{total} æˆåŠŸ")
        
        for stage, success in results.items():
            status = "âœ…" if success else "âŒ"
            print(f"   {status} {stage} æ¨¡å‹")
        
        if successful > 0:
            print(f"\nğŸ‰ æˆåŠŸæ¨é€ {successful} ä¸ªæ¨¡å‹!")
            print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
            print("   ollama run questions-gen-final 'Generate a calculus problem:'")
            print("   ollama run questions-gen-stage2 'Create a geometry problem:'")
    
    # ä½¿ç”¨æŒ‡å—ç”Ÿæˆ
    elif input("æ˜¯å¦ç”ŸæˆOllamaä½¿ç”¨æŒ‡å—? (y/N): ").lower().startswith('y'):
        print("\nğŸ“š ç”Ÿæˆä½¿ç”¨æŒ‡å—...")
        guide_path = ollama.save_usage_guide()
        print(f"âœ… ä½¿ç”¨æŒ‡å—å·²ä¿å­˜åˆ°: {guide_path}")
    
    # æµ‹è¯•ç°æœ‰æ¨¡å‹
    elif existing_models and input("æ˜¯å¦æµ‹è¯•ç°æœ‰æ¨¡å‹? (y/N): ").lower().startswith('y'):
        test_model = existing_models[0]
        print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹: {test_model}")
        
        test_results = ollama.test_model_in_ollama(
            test_model,
            test_prompts=[
                "Generate a simple algebra problem:",
                "Create a calculus question:"
            ]
        )
        
        print(f"âœ… æµ‹è¯•å®Œæˆ! æˆåŠŸç‡: {test_results['success_rate']:.1%}")
    
    else:
        print("ğŸ“‹ æ¼”ç¤ºå®Œæˆï¼Œæœªæ‰§è¡Œæ¨é€æ“ä½œ")
    
    # 5. æ€»ç»“
    print(f"\nğŸ“‹ æ€»ç»“:")
    print("âœ… HuggingFaceæ¨¡å‹éªŒè¯å®Œæˆ")
    print("âœ… Ollamaç¯å¢ƒæ£€æŸ¥å®Œæˆ")
    print("âœ… æ¨é€åŠŸèƒ½æ¼”ç¤ºå®Œæˆ")
    
    print(f"\nğŸ’¡ åç»­ä½¿ç”¨å»ºè®®:")
    print("1. ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·: questions-gen ollama --push-all")
    print("2. æŸ¥çœ‹ä½¿ç”¨æŒ‡å—: questions-gen ollama --guide")
    print("3. æµ‹è¯•æ¨¡å‹: questions-gen ollama --test questions-gen-final")
    print("4. APIè°ƒç”¨: curl http://localhost:11434/api/generate ...")


if __name__ == "__main__":
    main()
