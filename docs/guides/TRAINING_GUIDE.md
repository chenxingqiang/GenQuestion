# Questions-Gen ç«èµ›é¢˜ç›®ç”Ÿæˆæ¨¡å‹è®­ç»ƒæŒ‡å—

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

åŸºäºQwen3-14Bçš„ç«èµ›é¢˜ç›®ç”Ÿæˆæ¨¡å‹ï¼Œå®ç°ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼š
1. **åŸºç¡€é¢„è®­ç»ƒ** - åœ¨ç«èµ›é¢˜åº“ä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒ
2. **RL GRPOä¼˜åŒ–** - ä½¿ç”¨ç»„ç­–ç•¥å¼ºåŒ–å­¦ä¹ æå‡é¢˜ç›®è´¨é‡
3. **çŸ¥è¯†è’¸é¦** - é€šè¿‡æ•™å¸ˆæ¨¡å‹é›†ç¾¤è¿›ä¸€æ­¥ä¼˜åŒ–

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
Questions-Gen è®­ç»ƒç³»ç»Ÿ
â”œâ”€â”€ åŸºç¡€é¢„è®­ç»ƒ (Stage 1)
â”‚   â”œâ”€â”€ å†å²ç«èµ›é¢˜åº“ (50%)
â”‚   â”œâ”€â”€ æ¡ä»¶å˜å¼‚é¢˜ (30%)  
â”‚   â””â”€â”€ åˆ›æ–°é¢˜å‹ (20%)
â”œâ”€â”€ RL GRPOä¼˜åŒ– (Stage 2)
â”‚   â”œâ”€â”€ ç»„ç­–ç•¥ç”Ÿæˆ (8é¢˜/ç»„)
â”‚   â”œâ”€â”€ å¤šç»´å¥–åŠ±å‡½æ•°
â”‚   â””â”€â”€ åˆ›æ–°çº¦æŸå±‚
â””â”€â”€ çŸ¥è¯†è’¸é¦ (Stage 3)
    â”œâ”€â”€ DeepSeek-R1 (éš¾åº¦é¢„æµ‹)
    â”œâ”€â”€ é€»è¾‘ä¸¥è°¨æ€§æ£€æŸ¥
    â”œâ”€â”€ åˆ›æ–°æ€§è¯„ä¼°
    â””â”€â”€ æ•™è‚²ä»·å€¼è¯„åˆ†
```

## ğŸ“¦ ç¯å¢ƒå‡†å¤‡

### ç¡¬ä»¶è¦æ±‚
- **GPU**: å»ºè®®8GB+ VRAM (æ”¯æŒQwen3-14B 4bit)
- **å†…å­˜**: 16GB+ RAM
- **å­˜å‚¨**: 10GB+ å¯ç”¨ç©ºé—´

### ä¾èµ–å®‰è£…

```bash
# å®‰è£…Unsloth (GPUç‰ˆæœ¬)
pip install unsloth[cu118]  # CUDA 11.8
# æˆ–
pip install unsloth[cu121]  # CUDA 12.1

# å®‰è£…å…¶ä»–ä¾èµ–
pip install torch transformers datasets
pip install scikit-learn pandas numpy
pip install accelerate bitsandbytes
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. è¿è¡Œæ¼”ç¤º

```bash
# åŸºç¡€æµ‹è¯• (CPUå³å¯)
python quick_demo.py

# æ¨¡å‹éªŒè¯æ¼”ç¤º
python demo_model_validation.py
```

### 2. å®Œæ•´è®­ç»ƒ

```bash
# éœ€è¦8GB+ GPUå†…å­˜
python questions_gen_training.py
```

### 3. è‡ªå®šä¹‰é…ç½®

```python
from questions_gen_training import TrainingConfig

# ä¿®æ”¹è®­ç»ƒå‚æ•°
TrainingConfig.MAX_STEPS_STAGE1 = 200
TrainingConfig.GROUP_SIZE = 16
TrainingConfig.LEARNING_RATE = 1e-4
```

## âš™ï¸ æ ¸å¿ƒç»„ä»¶

### 1. åˆ›æ–°çº¦æŸå±‚ (NoveltyConstraint)
- **åŠŸèƒ½**: é˜²æ­¢é‡å¤é¢˜ç›®ç”Ÿæˆ
- **åŸç†**: åŸºäºTF-IDFå‘é‡ç›¸ä¼¼åº¦æ£€æµ‹
- **é˜ˆå€¼**: ç›¸ä¼¼åº¦>0.85æ—¶æ–½åŠ æƒ©ç½š

```python
class NoveltyConstraint(nn.Module):
    def forward(self, x, current_question=""):
        # è®¡ç®—ä¸å†å²é¢˜ç›®ç›¸ä¼¼åº¦
        # è¶…è¿‡é˜ˆå€¼åˆ™æƒ©ç½šè¾“å‡º
        return x * penalty_factor if similarity > threshold else x
```

### 2. å¥–åŠ±å‡½æ•° (RewardCalculator)

å¤šç»´åº¦è¯„ä¼°ä½“ç³»ï¼š
- **éš¾åº¦åˆ†æ** (40%): åŸºäºå…³é”®è¯å’Œæ–‡æœ¬é•¿åº¦
- **åˆ›æ–°æ€§** (30%): ä¸å†å²é¢˜ç›®çš„å·®å¼‚åº¦
- **é€»è¾‘ä¸¥è°¨æ€§** (20%): æ¨ç†è¯æ±‡å¯†åº¦
- **å¤šæ ·æ€§** (10%): ç»„å†…é¢˜ç›®å·®å¼‚

```python
reward = 0.4*difficulty + 0.3*novelty + 0.2*rigor + 0.1*diversity
```

### 3. GRPOç»„ç­–ç•¥ä¼˜åŒ–

```python
# æ¯ç»„ç”Ÿæˆ8é“é¢˜ç›®
group_questions = generate_question_group()

# è®¡ç®—å¥–åŠ±å¹¶é€‰æ‹©åŸºå‡†
baseline = median(rewards)
advantages = [r - baseline for r in rewards]

# æ¢¯åº¦æ›´æ–°
âˆ‡J(Î¸) = E[(R(Q) - R(baseline)) * âˆ‡log p_Î¸(Q)]
```

## ğŸ“Š è®­ç»ƒæµç¨‹

### é˜¶æ®µ1: åŸºç¡€é¢„è®­ç»ƒ
```python
trainer.stage1_basic_training()
# - 200æ­¥ç›‘ç£å¾®è°ƒ
# - æ··åˆé¢˜å‹è®­ç»ƒæ•°æ®
# - LoRAé«˜æ•ˆå¾®è°ƒ
```

### é˜¶æ®µ2: RL GRPOä¼˜åŒ–  
```python
trainer.stage2_grpo_training()
# - 100æ­¥å¼ºåŒ–å­¦ä¹ 
# - 8é¢˜ç»„ç­–ç•¥ç”Ÿæˆ
# - å¤šç»´å¥–åŠ±ä¼˜åŒ–
```

### é˜¶æ®µ3: çŸ¥è¯†è’¸é¦
```python
trainer.stage3_distillation()
# - 80æ­¥æ•™å¸ˆæŒ‡å¯¼
# - DeepSeek-R1è¯„ä¼°
# - å¯¹æŠ—è’¸é¦æå‡
```

## ğŸ¯ å…³é”®ç‰¹æ€§

### âœ¨ åˆ›æ–°ç‚¹
1. **ç»„ç­–ç•¥GRPO**: 8é¢˜å¹¶è¡Œç”Ÿæˆï¼Œå¯¹æ¯”ä¼˜åŒ–
2. **åˆ›æ–°çº¦æŸ**: TF-IDFç›¸ä¼¼åº¦é˜²é‡å¤
3. **å¤šç»´å¥–åŠ±**: éš¾åº¦+åˆ›æ–°+ä¸¥è°¨+å¤šæ ·æ€§
4. **æ¸è¿›è®­ç»ƒ**: ä¸‰é˜¶æ®µé€’è¿›ä¼˜åŒ–

### ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–
- **4bité‡åŒ–**: èŠ‚çœ50%æ˜¾å­˜
- **LoRAå¾®è°ƒ**: ä»…æ›´æ–°1-10%å‚æ•°  
- **æ¢¯åº¦ç´¯ç§¯**: æ¨¡æ‹Ÿå¤§batchè®­ç»ƒ
- **æ£€æŸ¥ç‚¹ä¿å­˜**: æ”¯æŒè®­ç»ƒæ¢å¤

## ğŸ”§ é…ç½®å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `MAX_SEQ_LENGTH` | 2048 | æœ€å¤§åºåˆ—é•¿åº¦ |
| `BATCH_SIZE` | 2 | æ‰¹æ¬¡å¤§å° |
| `LEARNING_RATE` | 2e-4 | å­¦ä¹ ç‡ |
| `GROUP_SIZE` | 8 | GRPOç»„å¤§å° |
| `LORA_R` | 32 | LoRAç§© |

## ğŸ“ è¾“å‡ºæ–‡ä»¶

```
checkpoints/
â”œâ”€â”€ stage1_basic/     # åŸºç¡€é¢„è®­ç»ƒæ¨¡å‹
â”œâ”€â”€ stage2_grpo/      # GRPOä¼˜åŒ–æ¨¡å‹  
â””â”€â”€ stage3_final/     # æœ€ç»ˆè’¸é¦æ¨¡å‹

logs/                 # è®­ç»ƒæ—¥å¿—
data/                 # è®­ç»ƒæ•°æ®ç¼“å­˜
```

## ğŸ§ª æ¨ç†æµ‹è¯•

```python
# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
trainer = QuestionsGenTrainer()

# ç”Ÿæˆé¢˜ç›®
messages = [{"role": "user", "content": "è¯·ç”Ÿæˆä¸€é“æ•°å­¦åˆ†æç«èµ›é¢˜ç›®"}]
response = trainer.model.generate(...)
```

## âš ï¸ å¸¸è§é—®é¢˜

### 1. **CUDAå†…å­˜ä¸è¶³**
```python
# å‡å°‘batch size
TrainingConfig.BATCH_SIZE = 1
TrainingConfig.GROUP_SIZE = 4
```

### 2. **ç½‘ç»œè¿æ¥é—®é¢˜**
```bash
# è®¾ç½®HuggingFaceé•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
```

### 3. **ä¾èµ–ç‰ˆæœ¬å†²çª**
```bash
# ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ
conda create -n questions-gen python=3.9
conda activate questions-gen
```

## ğŸ”„ æ‰©å±•åŠŸèƒ½

### 1. è‡ªå®šä¹‰æ•°æ®é›†
```python
def load_custom_dataset():
    # åŠ è½½ä½ çš„ç«èµ›é¢˜åº“
    return custom_dataframe

data_preparer.load_competition_datasets = load_custom_dataset
```

### 2. æ•™å¸ˆæ¨¡å‹é›†æˆ
```python
def call_teacher_model(question):
    # è°ƒç”¨GPT-4/Claudeç­‰API
    return evaluation_score

# åœ¨stage3_distillationä¸­é›†æˆ
```

### 3. è¯„ä¼°æŒ‡æ ‡
```python
def evaluate_generated_questions(questions):
    # å®ç°è‡ªå®šä¹‰è¯„ä¼°é€»è¾‘
    return metrics_dict
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [Unslothæ–‡æ¡£](https://docs.unsloth.ai/)
- [Qwen3æ¨¡å‹](https://huggingface.co/Qwen/Qwen3-14B)
- [GRPOè®ºæ–‡](https://arxiv.org/abs/2402.14740)
- [LoRAå¾®è°ƒ](https://arxiv.org/abs/2106.09685)

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼

## ğŸ“„ è®¸å¯è¯

Apache License 2.0 - è¯¦è§LICENSEæ–‡ä»¶
