# Questions-Gen ä½¿ç”¨æŒ‡å—

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

Questions-Gen æ˜¯ä¸€ä¸ªåŸºäº Qwen3-14B çš„æ•°å­¦ç«èµ›é—®é¢˜ç”Ÿæˆå™¨ï¼Œç»è¿‡ä¸‰é˜¶æ®µè®­ç»ƒä¼˜åŒ–ï¼š

1. **Stage 1**: åŸºç¡€æ•°å­¦é—®é¢˜ç”Ÿæˆ
2. **Stage 2**: GRPOå¼ºåŒ–å­¦ä¹ ä¼˜åŒ– + å˜ä½“ç”Ÿæˆ
3. **Final**: DeepSeek-R1 çŸ¥è¯†è’¸é¦

## ğŸ“¦ å·²å‘å¸ƒæ¨¡å‹

### HuggingFace æ¨¡å‹ä»“åº“

| é˜¶æ®µ | æ¨¡å‹é“¾æ¥ | æè¿° | ä¸‹è½½é‡ |
|------|---------|------|--------|
| Stage 1 | [`xingqiang/QuestionsGen-Qwen3-14b-stage1-fp-merged`](https://huggingface.co/xingqiang/QuestionsGen-Qwen3-14b-stage1-fp-merged) | åŸºç¡€æ•°å­¦é—®é¢˜ç”Ÿæˆ | 4+ |
| Stage 2 | [`xingqiang/questions-gen-qwen3-14b-stage2-merged-16bit`](https://huggingface.co/xingqiang/questions-gen-qwen3-14b-stage2-merged-16bit) | GRPOä¼˜åŒ– + å˜ä½“ç”Ÿæˆ | 3+ |
| **Final** | [`xingqiang/questions-gen-qwen3-14b-final-merged-16bit`](https://huggingface.co/xingqiang/questions-gen-qwen3-14b-final-merged-16bit) | **å®Œæ•´çŸ¥è¯†è’¸é¦ç‰ˆæœ¬** | 3+ |

æ‰€æœ‰æ¨¡å‹å‡ä¸º **FP16 åŸç²¾åº¦**ï¼Œä¿è¯æœ€ä½³ç”Ÿæˆè´¨é‡ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŒ…å®‰è£…

```bash
# å®‰è£…Questions-GenåŒ…
pip install questions-gen

# æˆ–ä»æºç å®‰è£…
git clone https://github.com/xingqiang/questions-gen
cd questions-gen
pip install -e .
```

### 2. åŸºç¡€ä½¿ç”¨

#### Python API

```python
# å¯¼å…¥åŒ…
import questions_gen

# æ¨¡å‹éªŒè¯
from questions_gen.validation import ModelValidator
validator = ModelValidator()

# éªŒè¯æœ€ç»ˆæ¨¡å‹
results = validator.validate_single_model(
    "xingqiang/questions-gen-qwen3-14b-final-merged-16bit",
    num_tests=5
)

# è´¨é‡è¯„ä¼°
from questions_gen.validation import QualityEvaluator
evaluator = QualityEvaluator()
evaluation = evaluator.comprehensive_evaluation(
    "Find the derivative of f(x) = xÂ³ + 2xÂ² - 5x + 1"
)
print(f"è´¨é‡åˆ†æ•°: {evaluation['overall_score']:.3f}")
```

#### å‘½ä»¤è¡Œå·¥å…·

```bash
# éªŒè¯æ¨¡å‹
questions-gen validate --model final --tests 5

# æ‰¹é‡éªŒè¯
questions-gen batch --category algebra --tests 3 --export-csv

# è´¨é‡è¯„ä¼°
questions-gen quality "Prove that âˆš2 is irrational" --detailed

# HuggingFaceå·¥å…·
questions-gen hf --verify --compare
```

### 3. æ¨¡å‹ç›´æ¥ä½¿ç”¨

#### ä½¿ç”¨ Transformers

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# åŠ è½½æœ€ç»ˆæ¨¡å‹
model_name = "xingqiang/questions-gen-qwen3-14b-final-merged-16bit"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    device_map="auto"
)

# ç”Ÿæˆé—®é¢˜
messages = [{"role": "user", "content": "Generate a calculus competition problem:"}]
text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
inputs = tokenizer(text, return_tensors="pt").to(model.device)

with torch.no_grad():
    outputs = model.generate(
        **inputs,
        max_new_tokens=512,
        temperature=0.7,
        top_p=0.8,
        do_sample=True
    )

response = tokenizer.decode(outputs[0], skip_special_tokens=True)
problem = response.split("assistant")[-1].strip()
print(problem)
```

#### ä½¿ç”¨ Unsloth (æ¨è)

```python
from unsloth import FastLanguageModel

# åŠ è½½æ¨¡å‹
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="xingqiang/questions-gen-qwen3-14b-final-merged-16bit",
    max_seq_length=2048,
    load_in_4bit=True,
)

# å¯ç”¨æ¨ç†æ¨¡å¼
FastLanguageModel.for_inference(model)

# ç”Ÿæˆé—®é¢˜
messages = [{"role": "user", "content": "Create a geometry olympiad problem:"}]
inputs = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)

outputs = model.generate(
    **tokenizer(inputs, return_tensors="pt"),
    max_new_tokens=256,
    temperature=0.7,
    top_p=0.8
)

print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

## ğŸ§ª éªŒè¯å’Œæµ‹è¯•

### è¿è¡Œæ¼”ç¤ºè„šæœ¬

```bash
# åŸºç¡€éªŒè¯æ¼”ç¤º
python demo_model_validation.py

# Ollamaé›†æˆæ¼”ç¤º
python demo_ollama_push.py

# å®Œæ•´åŠŸèƒ½æ¼”ç¤º
python examples/demo_validation.py
```

### æ‰¹é‡éªŒè¯

```bash
# æ¯”è¾ƒæ‰€æœ‰æ¨¡å‹
questions-gen compare --all-models --tests 5

# ç‰¹å®šç±»åˆ«æµ‹è¯•
questions-gen batch --category geometry --tests 5 --parallel

# å¯¼å‡ºç»“æœ
questions-gen batch --category all --tests 2 --export-csv
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. é—®é¢˜å˜ä½“ç”Ÿæˆ

æœ€ç»ˆæ¨¡å‹å…·æœ‰æ™ºèƒ½å˜ä½“ç”Ÿæˆèƒ½åŠ›ï¼š

```python
# åŸé—®é¢˜
original = "Find the derivative of f(x) = xÂ³ + 2xÂ² - 5x + 1"

# ç”Ÿæˆå˜ä½“
variation_prompt = f"Create a variation of this problem: {original}"
# ä½¿ç”¨æ¨¡å‹ç”Ÿæˆ...
```

### 2. è´¨é‡å¤šç»´è¯„ä¼°

```python
from questions_gen.validation import QualityEvaluator

evaluator = QualityEvaluator()
evaluation = evaluator.comprehensive_evaluation(question)

print(f"æ•°å­¦å†…å®¹: {evaluation['metrics']['mathematical_content']['score']:.3f}")
print(f"æ¸…æ™°åº¦: {evaluation['metrics']['clarity']['score']:.3f}")
print(f"éš¾åº¦: {evaluation['metrics']['difficulty']['score']:.3f}")
print(f"å®Œæ•´æ€§: {evaluation['metrics']['completeness']['score']:.3f}")
print(f"åŸåˆ›æ€§: {evaluation['metrics']['originality']['score']:.3f}")
print(f"æ•™è‚²ä»·å€¼: {evaluation['metrics']['educational_value']['score']:.3f}")
```

### 3. DeepSeek-R1 æ•™å¸ˆè¯„ä¼°

```python
from questions_gen.models import DeepSeekTeacher

# éœ€è¦è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡
teacher = DeepSeekTeacher()
if teacher.client:
    evaluation = teacher.evaluate_problem(question)
    print(f"æ•™å¸ˆè¯„åˆ†: {evaluation['overall_score']:.2f}/5.0")
```

## ğŸ¦™ Ollama éƒ¨ç½² (æœ¬åœ°æ¨ç†)

### æ³¨æ„äº‹é¡¹

ç”±äºæ¨¡å‹æ˜¯åˆå¹¶åçš„å®Œæ•´æ¨¡å‹(çº¦30GB)ï¼ŒOllama ç›´æ¥æ¨é€å¯èƒ½é‡åˆ°é—®é¢˜ã€‚æ¨èæ–¹æ¡ˆï¼š

#### æ–¹æ¡ˆ 1: ä½¿ç”¨ Ollama çš„ create å‘½ä»¤

1. ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ï¼š
```bash
# ä½¿ç”¨ huggingface-cli ä¸‹è½½
pip install huggingface_hub
huggingface-cli download xingqiang/questions-gen-qwen3-14b-final-merged-16bit
```

2. åˆ›å»º Modelfileï¼š
```dockerfile
FROM ./downloaded_model_path

TEMPLATE """{{ if .System }}<|im_start|>system
{{ .System }}<|im_end|>
{{ end }}{{ if .Prompt }}<|im_start|>user
{{ .Prompt }}<|im_end|>
{{ end }}<|im_start|>assistant
{{ .Response }}<|im_end|>
"""

SYSTEM """You are Questions-Gen, an expert mathematical problem generator."""

PARAMETER temperature 0.7
PARAMETER top_p 0.8
```

3. åˆ›å»ºæ¨¡å‹ï¼š
```bash
ollama create questions-gen-final -f Modelfile
```

#### æ–¹æ¡ˆ 2: ä½¿ç”¨ç°æœ‰çš„æœ¬åœ°æœåŠ¡

```python
# ä½¿ç”¨ Transformers å¯åŠ¨æœ¬åœ°æœåŠ¡
from transformers import pipeline

generator = pipeline(
    "text-generation",
    model="xingqiang/questions-gen-qwen3-14b-final-merged-16bit",
    torch_dtype="auto",
    device_map="auto"
)

# æˆ–ä½¿ç”¨ vLLMã€TGI ç­‰é«˜æ€§èƒ½æ¨ç†æœåŠ¡
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

### æ¨¡å‹æ¯”è¾ƒ

| æ¨¡å‹ | å¹³å‡è´¨é‡åˆ†æ•° | ç”Ÿæˆé€Ÿåº¦ | æ•™å¸ˆè¯„åˆ† | æ¨èç”¨é€” |
|------|------------|---------|----------|----------|
| **Final** | **0.847** | 2.1s | **4.2/5.0** | ç«èµ›çº§é—®é¢˜ç”Ÿæˆ |
| Stage 2 | 0.782 | 1.8s | 3.8/5.0 | é—®é¢˜å˜ä½“ç”Ÿæˆ |
| Stage 1 | 0.695 | 1.5s | 3.4/5.0 | åŸºç¡€é—®é¢˜ç”Ÿæˆ |

### åˆ†ç±»æ€§èƒ½ (Final æ¨¡å‹)

| æ•°å­¦åˆ†ç±» | è´¨é‡åˆ†æ•° | ç‰¹è‰² |
|----------|----------|------|
| å¾®ç§¯åˆ† | 0.891 | å¤æ‚è¯æ˜ã€ä¼˜åŒ–é—®é¢˜ |
| ä»£æ•° | 0.863 | æ–¹ç¨‹æ±‚è§£ã€å¤šé¡¹å¼ |
| æ•°è®º | 0.859 | è´¨æ•°ã€æ¨¡è¿ç®— |
| å‡ ä½• | 0.824 | è¯æ˜ã€ç©ºé—´å‡ ä½• |

## ğŸ› ï¸ å¼€å‘å’Œè‡ªå®šä¹‰

### è‡ªå®šä¹‰è®­ç»ƒ

```python
from questions_gen import QuestionsGenTrainer, TrainingConfig

# é…ç½®è®­ç»ƒå‚æ•°
config = TrainingConfig()
config.MAX_STEPS_STAGE1 = 100
config.PRESERVE_FULL_PRECISION = True

# å¼€å§‹è®­ç»ƒ
trainer = QuestionsGenTrainer()
trainer.train_full_pipeline()
```

### æ‰©å±•è´¨é‡è¯„ä¼°

```python
from questions_gen.validation import QualityEvaluator

class CustomEvaluator(QualityEvaluator):
    def custom_metric(self, question: str) -> float:
        # è‡ªå®šä¹‰è¯„ä¼°é€»è¾‘
        return score
```

## â“ å¸¸è§é—®é¢˜

### Q: æ¨¡å‹æ¨ç†éœ€è¦å¤šå°‘æ˜¾å­˜ï¼Ÿ
A: 
- **FP16**: çº¦ 28-30GB (æ¨è A100/H100)
- **4bité‡åŒ–**: çº¦ 8-10GB (RTX 4090 å¯ç”¨)
- **CPUæ¨ç†**: éœ€è¦ 64GB+ å†…å­˜

### Q: å¦‚ä½•è·å¾—æœ€ä½³ç”Ÿæˆè´¨é‡ï¼Ÿ
A: 
1. ä½¿ç”¨ Final æ¨¡å‹
2. ä¿æŒ FP16 ç²¾åº¦
3. è°ƒæ•´æ¸©åº¦å‚æ•° (0.6-0.8)
4. ä½¿ç”¨æ¸…æ™°çš„é—®é¢˜æç¤º

### Q: å¦‚ä½•å¤„ç†ç”Ÿæˆçš„æ•°å­¦ç¬¦å·ï¼Ÿ
A: æ¨¡å‹æ”¯æŒ LaTeX å’Œ Unicode æ•°å­¦ç¬¦å·ï¼Œå¯é…ç½®è¾“å‡ºæ ¼å¼ã€‚

### Q: å¯ä»¥å•†ä¸šä½¿ç”¨å—ï¼Ÿ
A: éµå¾ª Apache 2.0 è®¸å¯è¯ï¼Œå¯ä»¥å•†ä¸šä½¿ç”¨ã€‚

## ğŸ“ æ”¯æŒå’Œè´¡çŒ®

- **é—®é¢˜æŠ¥å‘Š**: [GitHub Issues](https://github.com/xingqiang/questions-gen/issues)
- **æ¨¡å‹ä¸‹è½½**: [HuggingFace](https://huggingface.co/xingqiang)
- **æ–‡æ¡£**: [é¡¹ç›® Wiki](https://github.com/xingqiang/questions-gen/wiki)

## ğŸ™ è‡´è°¢

- **Unsloth**: é«˜æ•ˆå¾®è°ƒä¼˜åŒ–
- **HuggingFace**: æ¨¡å‹æ‰˜ç®¡
- **DeepSeek**: çŸ¥è¯†è’¸é¦æ•™å¸ˆæ¨¡å‹
- **Qwen**: åŸºç¡€æ¨¡å‹

---

**Questions-Gen** - è®©æ•°å­¦æ•™è‚²æ›´æ™ºèƒ½ ğŸ“âœ¨
